{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.__init__ import *\n",
    "img_folder = \"G:/Github/ocr_hanviet/data/test\"\n",
    "pdf_folder = \"G:/Github/ocr_hanviet/data/pdf\"\n",
    "output_path = \"G:/Github/ocr_hanviet/data/ocr_output.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447f1509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHUYá»‚N Tá»ª PDF SANG áº¢NH JPG\n",
    "for tap_number in range(6, 11): \n",
    "    pdf_path = f\"{pdf_folder}/tap_{tap_number}.PDF\"\n",
    "\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ KhÃ´ng thá»ƒ má»Ÿ file {pdf_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    for page_number in range(len(doc)):\n",
    "        try:\n",
    "            page = doc.load_page(page_number)\n",
    "            pix = page.get_pixmap(dpi=300)\n",
    "            output_path = f\"{img_folder}/page_{tap_number}_{page_number + 1}.jpg\"\n",
    "            pix.save(output_path)\n",
    "            print(f\"âœ… ÄÃ£ lÆ°u: {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Lá»—i khi xá»­ lÃ½ trang {page_number + 1} cá»§a táº­p {tap_number}: {e}\")\n",
    "\n",
    "    doc.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT_OCR:\n",
    "    def __init__(self, api_key: str, img_folder: str):\n",
    "        self.api_key = api_key\n",
    "        self.img_folder = img_folder\n",
    "        self.last_section_id = None\n",
    "        openai.api_key = self.api_key\n",
    "\n",
    "    def _load_image(self, image_path: str) -> Optional[str]:\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"âŒ File khÃ´ng tá»“n táº¡i: {image_path}\")\n",
    "            return None\n",
    "        try:\n",
    "            with open(image_path, \"rb\") as f:\n",
    "                return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ KhÃ´ng thá»ƒ Ä‘á»c áº£nh: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _call_gpt_ocr(self, image_data_url: str) -> Optional[str]:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": (\n",
    "                            \"Báº¡n lÃ  trá»£ lÃ½ OCR chuyÃªn nghiá»‡p. HÃ£y trÃ­ch xuáº¥t tá»«ng DÃ’NG vÄƒn báº£n tiáº¿ng Viá»‡t in trong áº£nh. \"\n",
    "                            \"Vá»›i má»—i dÃ²ng, tráº£ vá» má»™t dictionary cÃ³: \"\n",
    "                            \"'text': ná»™i dung cá»§a dÃ²ng, vÃ  'bbox': tá»a Ä‘á»™ bounding box dáº¡ng [x0, y0, x1, y1]. \"\n",
    "                            \"Chá»‰ tráº£ vá» má»™t list cÃ¡c dictionaries, khÃ´ng giáº£i thÃ­ch thÃªm.\"\n",
    "                        )\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\"url\": image_data_url}\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                temperature=0,\n",
    "                max_tokens=2000,\n",
    "            )\n",
    "            return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error calling GPT-4o API: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _parse_response(self, content: str) -> List[Dict]:\n",
    "        if not content:\n",
    "            return []\n",
    "\n",
    "        content_clean = content.strip()\n",
    "        if content_clean.startswith(\"```\"):\n",
    "            content_clean = re.sub(r\"^```(?:json)?\\s*\", \"\", content_clean)\n",
    "            content_clean = re.sub(r\"\\s*```$\", \"\", content_clean)\n",
    "\n",
    "        try:\n",
    "            ocr_lines = json.loads(content_clean)\n",
    "            if isinstance(ocr_lines, list):\n",
    "                return ocr_lines\n",
    "        except json.JSONDecodeError:\n",
    "            try:\n",
    "                print(\"âš ï¸ JSON lá»—i, thá»­ parse báº±ng ast...\")\n",
    "                ocr_lines = ast.literal_eval(content_clean)\n",
    "                if isinstance(ocr_lines, list):\n",
    "                    return ocr_lines\n",
    "            except Exception as e_ast:\n",
    "                print(\"âŒ Parse tháº¥t báº¡i:\", e_ast)\n",
    "                print(\"ğŸ” Content preview:\", repr(content_clean[:300]))\n",
    "        return []\n",
    "\n",
    "    def _build_dataframe(self, ocr_lines: List[Dict], image_name: str, paper_name:str, file_id: str) -> pd.DataFrame:\n",
    "        data = []\n",
    "        current_section = None\n",
    "        sentence_buffer = []\n",
    "        bbox_buffer = []\n",
    "\n",
    "        def is_sentence_ending(text: str) -> bool:\n",
    "            text = text.strip()\n",
    "            return (\n",
    "                text.endswith((\".\", \":\", \"!\", \"?\"))\n",
    "                or text.isupper()\n",
    "                or text.startswith(\"-\")\n",
    "                or len(text.split()) <= 3\n",
    "            )\n",
    "\n",
    "        for idx, line in enumerate(ocr_lines):\n",
    "            if not isinstance(line, dict) or \"text\" not in line:\n",
    "                continue\n",
    "\n",
    "            text = line[\"text\"].strip()\n",
    "            if not text:\n",
    "                continue\n",
    "            bbox = line.get(\"bbox\", [0, 0, 0, 0])\n",
    "            if not isinstance(bbox, list) or len(bbox) != 4:\n",
    "                bbox = [0, 0, 0, 0]\n",
    "\n",
    "            match = re.search(r\"(quyá»ƒn\\s+\\w+)\", text, re.IGNORECASE)\n",
    "            if match:\n",
    "                current_section = match.group(1)\n",
    "                self.last_section_id = current_section  # âœ… Cáº­p nháº­t section ID dÃ¹ng cho áº£nh tiáº¿p theo\n",
    "\n",
    "            sentence_buffer.append(text)\n",
    "            bbox_buffer.append(bbox)\n",
    "\n",
    "            next_line = ocr_lines[idx + 1][\"text\"].strip() if idx + 1 < len(ocr_lines) else \"\"\n",
    "            ends_now = is_sentence_ending(text)\n",
    "            starts_new = next_line.startswith(\"-\") or next_line.isupper()\n",
    "\n",
    "            if ends_now or starts_new or idx == len(ocr_lines) - 1:\n",
    "                full_text = \" \".join(sentence_buffer).strip()\n",
    "                sentence_buffer.clear()\n",
    "\n",
    "                sentences = [s.strip() for s in full_text.split('.') if s.strip()]\n",
    "                if not sentences:\n",
    "                    sentences = [full_text]\n",
    "\n",
    "                for i, sent in enumerate(sentences):\n",
    "                    full_sentence = sent if sent.endswith(('.', '!', '?', ':')) else sent + '.'\n",
    "                    data.append({\n",
    "                        \"File_id\": file_id,\n",
    "                        \"Paper_id\": paper_name,\n",
    "                        \"Section_id\": current_section or self.last_section_id,\n",
    "                        \"Page_id\": image_name,\n",
    "                        \"BBox\": bbox_buffer[0] if bbox_buffer else [0, 0, 0, 0],\n",
    "                        \"Text\": full_text if i == 0 else \"\",\n",
    "                        \"Sentence\": full_sentence\n",
    "                    })\n",
    "                bbox_buffer.clear()\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    def ocr_image(self, image_path: str, image_name: str, paper_name:str, file_id: str = \"HVE_009\") -> pd.DataFrame:\n",
    "        print(f\"ğŸ“¤ Äang OCR: {image_name}\")\n",
    "        image_b64 = self._load_image(image_path)\n",
    "        if not image_b64:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        content = self._call_gpt_ocr(f\"data:image/jpeg;base64,{image_b64}\")\n",
    "        if not content:\n",
    "            print(\"âŒ KhÃ´ng nháº­n Ä‘Æ°á»£c pháº£n há»“i tá»« GPT\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        ocr_lines = self._parse_response(content)\n",
    "        if not ocr_lines:\n",
    "            print(\"âŒ OCR lines rá»—ng\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        return self._build_dataframe(ocr_lines, image_name, paper_name, file_id)\n",
    "\n",
    "    def ocr_folder_parallel(self, max_workers: int = 4, output_file: Optional[str] = None) -> pd.DataFrame:\n",
    "        if not os.path.exists(self.img_folder):\n",
    "            print(f\"âŒ Folder khÃ´ng tá»“n táº¡i: {self.img_folder}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        files = sorted(f for f in os.listdir(self.img_folder) if f.lower().startswith(\"page_\") and f.lower().endswith(\".jpg\"))\n",
    "        if not files:\n",
    "            print(\"âŒ KhÃ´ng tÃ¬m tháº¥y áº£nh há»£p lá»‡\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        print(f\"ğŸ–¼ï¸ TÃ¬m tháº¥y {len(files)} áº£nh, báº¯t Ä‘áº§u OCR vá»›i {max_workers} workers...\")\n",
    "\n",
    "        results = []\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_file = {\n",
    "                executor.submit(self.ocr_image, os.path.join(self.img_folder, f), f.split(\"_\")[-1].replace(\".jpg\", \"\"), f.split(\"_\")[1]): f\n",
    "                for f in files\n",
    "            }\n",
    "\n",
    "            for i, future in enumerate(as_completed(future_to_file), 1):\n",
    "                file = future_to_file[future]\n",
    "                try:\n",
    "                    df = future.result()\n",
    "                    if not df.empty:\n",
    "                        results.append(df)\n",
    "\n",
    "                        # âœ… Ghi append vÃ o output_file ngay sau khi cÃ³ káº¿t quáº£\n",
    "                        if output_file:\n",
    "                            write_header = not os.path.exists(output_file)\n",
    "                            df.to_csv(output_file, mode='a', index=False, encoding='utf-8-sig', header=write_header)\n",
    "\n",
    "                        print(f\"âœ… ({i}/{len(files)}) {file}: {len(df)} dÃ²ng\")\n",
    "                    else:\n",
    "                        print(f\"âš ï¸ ({i}/{len(files)}) {file}: KhÃ´ng cÃ³ dÃ²ng\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ ({i}/{len(files)}) {file}: {e}\")\n",
    "\n",
    "        if results:\n",
    "            df_all = pd.concat(results, ignore_index=True)\n",
    "            print(f\"ğŸ“Š Tá»•ng cá»™ng {len(df_all)} dÃ²ng tá»« {len(results)} áº£nh\")\n",
    "            if output_file:\n",
    "                try:\n",
    "                    df_all.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "                    print(f\"ğŸ’¾ ÄÃ£ lÆ°u káº¿t quáº£ vÃ o: {output_file}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ KhÃ´ng thá»ƒ lÆ°u file: {e}\")\n",
    "            return df_all\n",
    "        else:\n",
    "            print(\"âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u nÃ o Ä‘Æ°á»£c trÃ­ch xuáº¥t\")\n",
    "            return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ–¼ï¸ TÃ¬m tháº¥y 11 áº£nh, báº¯t Ä‘áº§u OCR vá»›i 10 workers...\n",
      "ğŸ“¤ Äang OCR: 1\n",
      "ğŸ“¤ Äang OCR: 2\n",
      "ğŸ“¤ Äang OCR: 3\n",
      "ğŸ“¤ Äang OCR: 4\n",
      "ğŸ“¤ Äang OCR: 5\n",
      "ğŸ“¤ Äang OCR: 6\n",
      "ğŸ“¤ Äang OCR: 7\n",
      "ğŸ“¤ Äang OCR: 8\n",
      "ğŸ“¤ Äang OCR: 9\n",
      "ğŸ“¤ Äang OCR: 189\n",
      "ğŸ“¤ Äang OCR: 2\n",
      "âœ… (1/11) page_6_2.jpg: 8 dÃ²ng\n",
      "âœ… (2/11) page_6_1.jpg: 6 dÃ²ng\n",
      "âœ… (3/11) page_7_2.jpg: 8 dÃ²ng\n",
      "âœ… (4/11) page_6_3.jpg: 17 dÃ²ng\n",
      "âœ… (5/11) page_6_5.jpg: 18 dÃ²ng\n",
      "âœ… (6/11) page_6_9.jpg: 18 dÃ²ng\n",
      "âœ… (7/11) page_6_8.jpg: 18 dÃ²ng\n",
      "âœ… (8/11) page_7_189.jpg: 15 dÃ²ng\n",
      "âœ… (9/11) page_6_4.jpg: 16 dÃ²ng\n",
      "âœ… (10/11) page_6_7.jpg: 17 dÃ²ng\n",
      "âœ… (11/11) page_6_6.jpg: 12 dÃ²ng\n",
      "ğŸ“Š Tá»•ng cá»™ng 153 dÃ²ng tá»« 11 áº£nh\n",
      "ğŸ’¾ ÄÃ£ lÆ°u káº¿t quáº£ vÃ o: G:/Github/ocr_hanviet/data/ocr_output.csv\n"
     ]
    }
   ],
   "source": [
    "extractor = GPT_OCR(api_key=OPENAI_API_KEY, img_folder=img_folder)\n",
    "df_all = extractor.ocr_folder_parallel(max_workers=10, output_file=output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
